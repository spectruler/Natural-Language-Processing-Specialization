{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trax : Ungraded Lecture Notebook\n",
    "\n",
    "In this notebook you'll get to know about the Trax framework and learn about some of its basic building blocks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Why Trax and not TensorFlow or PyTorch?\n",
    "\n",
    "TensorFlow and PyTorch are both extensive frameworks that can do almost anything in deep learning. They offer a lot of flexibility, but that often means verbosity of syntax and extra time to code.\n",
    "\n",
    "Trax is much more concise. It runs on a TensorFlow backend but allows you to train models with 1 line commands. Trax also runs end to end, allowing you to get data, model and train all with a single terse statements. This means you can focus on learning, instead of spending hours on the idiosyncrasies of big framework implementation.\n",
    "\n",
    "### Why not Keras then?\n",
    "\n",
    "Keras is now part of Tensorflow itself from 2.0 onwards. Also, trax is good for implementing new state of the art algorithms like Transformers, Reformers, BERT because it is actively maintained by Google Brain Team for advanced deep learning tasks. It runs smoothly on CPUs,GPUs and TPUs as well with comparatively lesser modifications in code.\n",
    "\n",
    "### How to Code in Trax\n",
    "Building models in Trax relies on 2 key concepts:- **layers** and **combinators**.\n",
    "Trax layers are simple objects that process data and perform computations. They can be chained together into composite layers using Trax combinators, allowing you to build layers and models of any complexity.\n",
    "\n",
    "### Trax, JAX, TensorFlow and Tensor2Tensor\n",
    "\n",
    "You already know that Trax uses Tensorflow as a backend, but it also uses the JAX library to speed up computation too. You can view JAX as an enhanced and optimized version of numpy. \n",
    "\n",
    "**Watch out for assignments which import `import trax.fastmath.numpy as np`. If you see this line, remember that when calling `np` you are really calling Trax’s version of numpy that is compatible with JAX.**\n",
    "\n",
    "As a result of this, where you used to encounter the type `numpy.ndarray` now you will find the type `jax.interpreters.xla.DeviceArray`.\n",
    "\n",
    "Tensor2Tensor is another name you might have heard. It started as an end to end solution much like how Trax is designed, but it grew unwieldy and complicated. So you can view Trax as the new improved version that operates much faster and simpler.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\n",
    "- JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Trax\n",
    "\n",
    "Trax has dependencies on JAX and some libraries like JAX which are yet to be supported in [Windows](https://github.com/google/jax/blob/1bc5896ee4eab5d7bb4ec6f161d8b2abb30557be/README.md#installation) but work well in Ubuntu and MacOS. We would suggest that if you are working on Windows, try to install Trax on WSL2. \n",
    "\n",
    "Official maintained documentation - [trax-ml](https://trax-ml.readthedocs.io/en/latest/) not to be confused with this [TraX](https://trax.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trax==1.3.1\n",
      "  Downloading trax-1.3.1-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[K     |████████████████████████████████| 347 kB 420 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.1.52-cp37-none-manylinux2010_x86_64.whl (33.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.1 MB 56 kB/s  eta 0:00:01     |██████████████████████████▏     | 27.0 MB 388 kB/s eta 0:00:16\n",
      "\u001b[?25hCollecting t5\n",
      "  Downloading t5-0.6.4-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 71 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 380 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/jaipal/anaconda3/lib/python3.7/site-packages (from trax==1.3.1) (1.18.1)\n",
      "Requirement already satisfied: six in /home/jaipal/anaconda3/lib/python3.7/site-packages (from trax==1.3.1) (1.14.0)\n",
      "Collecting funcsigs\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: scipy in /home/jaipal/anaconda3/lib/python3.7/site-packages (from trax==1.3.1) (1.4.1)\n",
      "Collecting jax\n",
      "  Downloading jax-0.1.75.tar.gz (426 kB)\n",
      "\u001b[K     |████████████████████████████████| 426 kB 477 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gym\n",
      "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 474 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 488 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.3.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 89 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 5.2 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensor2tensor\n",
      "  Downloading tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 21 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 2.5 kB/s eta 0:00:01     |█████████████████████▊          | 507.7 MB 434 kB/s eta 0:09:15\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/mesh-tensorflow/\u001b[0m\n",
      "\u001b[?25hCollecting mesh-tensorflow[transformer]>=0.1.13\n",
      "  Downloading mesh_tensorflow-0.1.16-py3-none-any.whl (305 kB)\n",
      "\u001b[K     |████████████████████████████████| 305 kB 55 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /home/jaipal/anaconda3/lib/python3.7/site-packages (from t5->trax==1.3.1) (3.4.5)\n",
      "Requirement already satisfied: pandas in /home/jaipal/anaconda3/lib/python3.7/site-packages (from t5->trax==1.3.1) (1.0.1)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-1.4.13-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 21 kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 316 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=2.7.0\n",
      "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
      "\u001b[K     |████████████████████████████████| 884 kB 39 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tfds-nightly\n",
      "  Downloading tfds_nightly-3.2.1.dev202009070105-py3-none-any.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 36 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/jaipal/anaconda3/lib/python3.7/site-packages (from t5->trax==1.3.1) (0.22.1)\n",
      "Requirement already satisfied: babel in /home/jaipal/anaconda3/lib/python3.7/site-packages (from t5->trax==1.3.1) (2.8.0)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: future in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (0.18.2)\n",
      "Requirement already satisfied: wrapt in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (3.13.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.23.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 275 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (4.42.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (2.22.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 526 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-datasets->trax==1.3.1) (19.3.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting opt_einsum\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 102 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 10 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from gym->trax==1.3.1) (1.3.0)\n",
      "Collecting tensorflow<2.4,>=2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 19 kB/s eta 0:00:011\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tf-slim/\u001b[0m\n",
      "\u001b[?25hCollecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 233 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 261 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 257 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.4 MB 116 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dopamine-rl\n",
      "  Downloading dopamine_rl-3.1.7-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 411 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensor2tensor->trax==1.3.1) (2.10.0)\n",
      "Collecting tensorflow-gan\n",
      "  Downloading tensorflow_gan-2.0.0-py2.py3-none-any.whl (365 kB)\n",
      "\u001b[K     |████████████████████████████████| 365 kB 86 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gevent in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensor2tensor->trax==1.3.1) (1.4.0)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.11.2-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 86 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pypng\n",
      "  Downloading pypng-0.0.20.tar.gz (649 kB)\n",
      "\u001b[K     |████████████████████████████████| 649 kB 18 kB/s eta 0:00:012     |██████████████████▋             | 378 kB 153 kB/s eta 0:00:02\n",
      "\u001b[?25hCollecting bz2file\n",
      "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
      "Requirement already satisfied: Pillow in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensor2tensor->trax==1.3.1) (7.0.0)\n",
      "Requirement already satisfied: sympy in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensor2tensor->trax==1.3.1) (1.5.1)\n",
      "Collecting kfac\n",
      "  Downloading kfac-0.2.2-py2.py3-none-any.whl (191 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 191 kB 54 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client\n",
      "  Downloading google_api_python_client-1.11.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 120 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flask in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensor2tensor->trax==1.3.1) (1.1.1)\n",
      "Collecting tensorflow-probability==0.7.0\n",
      "  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 437 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from pandas->t5->trax==1.3.1) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from pandas->t5->trax==1.3.1) (2019.3)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 29 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 101 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/jaipal/anaconda3/lib/python3.7/site-packages (from transformers>=2.7.0->t5->trax==1.3.1) (3.0.12)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 516 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/jaipal/anaconda3/lib/python3.7/site-packages (from transformers>=2.7.0->t5->trax==1.3.1) (20.1)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-3.0.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.5-cp37-cp37m-manylinux1_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 590 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from scikit-learn->t5->trax==1.3.1) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /home/jaipal/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-datasets->trax==1.3.1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: googleapis-common-protos in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow-datasets->trax==1.3.1) (1.51.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.1) (2.8)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.31.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 533 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax==1.3.1) (0.34.2)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 148 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 12 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 270 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 435 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.18.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 18 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa>=3.1.4 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from oauth2client->tensor2tensor->trax==1.3.1) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from oauth2client->tensor2tensor->trax==1.3.1) (0.2.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from oauth2client->tensor2tensor->trax==1.3.1) (0.4.8)\n",
      "Collecting flax>=0.2.0\n",
      "  Downloading flax-0.2.1-py3-none-any.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 480 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygame>=1.9.2\n",
      "  Downloading pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl (11.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.4 MB 407 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.2\n",
      "  Downloading tensorflow_hub-0.9.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 535 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: greenlet>=0.4.14 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from gevent->tensor2tensor->trax==1.3.1) (0.4.15)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.9.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from sympy->tensor2tensor->trax==1.3.1) (1.1.0)\n",
      "Collecting google-api-core<2dev,>=1.18.0\n",
      "  Downloading google_api_core-1.22.2-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 454 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.0.4-py2.py3-none-any.whl (9.1 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from google-api-python-client->tensor2tensor->trax==1.3.1) (1.20.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flask->tensor2tensor->trax==1.3.1) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flask->tensor2tensor->trax==1.3.1) (2.11.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flask->tensor2tensor->trax==1.3.1) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flask->tensor2tensor->trax==1.3.1) (1.0.0)\n",
      "Requirement already satisfied: decorator in /home/jaipal/anaconda3/lib/python3.7/site-packages (from tensorflow-probability==0.7.0->tensor2tensor->trax==1.3.1) (4.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from packaging->transformers>=2.7.0->t5->trax==1.3.1) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /home/jaipal/anaconda3/lib/python3.7/site-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly->t5->trax==1.3.1) (2.2.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 385 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 7.7 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: msgpack in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flax>=0.2.0->dopamine-rl->tensor2tensor->trax==1.3.1) (0.6.1)\n",
      "Requirement already satisfied: matplotlib in /home/jaipal/anaconda3/lib/python3.7/site-packages (from flax>=0.2.0->dopamine-rl->tensor2tensor->trax==1.3.1) (3.1.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from google-auth>=1.16.0->google-api-python-client->tensor2tensor->trax==1.3.1) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask->tensor2tensor->trax==1.3.1) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/jaipal/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax==1.3.1) (1.5.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from matplotlib->flax>=0.2.0->dopamine-rl->tensor2tensor->trax==1.3.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jaipal/anaconda3/lib/python3.7/site-packages (from matplotlib->flax>=0.2.0->dopamine-rl->tensor2tensor->trax==1.3.1) (1.1.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 510 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jax, gym, dill, promise, termcolor, pypng, bz2file, sacremoses\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.1.75-py3-none-any.whl size=492887 sha256=c712eea9c7410b4b5ba5d8081e37a5a933cbf922b83b14bcd742448cd40814af\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/f1/57/cd/d2be9716ab934107dfab56d909778f82a1c1e97909ca2f2c5b\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650891 sha256=5956f89af81b8b653c7b15db34183436a324b25c262591be93769a673135562f\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=bc831bc547a1d695e01a0130be0931ce6bd3816e021f5ee2d88171e76722e10f\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/72/6b/d5/5548aa1b73b8c3d176ea13f9f92066b02e82141549d90e2100\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=6d5d9c95009de55375f8faecd0dd9d781f0f2c0daadc309e788495af9df87738\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=ea69d1afcf00aae792fa3c996d424059585de149b1c63e87f500c83dd4b094df\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for pypng (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypng: filename=pypng-0.0.20-py3-none-any.whl size=67162 sha256=11a384c69071e04e4eef456359253d35c19ddad6da7b04ecb88eb03a5b98338f\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/54/64/43/dfd10cf95dc1687dc5350e861321ecd9a5d76b7c3d96fa1dc6\n",
      "  Building wheel for bz2file (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6882 sha256=3a329c6f3b24b7e83f5917f071ee6371e848dfd14712f21278fe13a70b56e043\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/85/ce/8d/b5f76b602b16a8a39f2ded74189cf5f09fc4a87bea16c54a8b\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=647f3c44177b3ad8ce732dd105440a51a10ca5a784c32c200a6a866d03868bc3\n",
      "  Stored in directory: /home/jaipal/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built jax gym dill promise termcolor pypng bz2file sacremoses\n",
      "\u001b[31mERROR: google-api-core 1.22.2 has requirement google-auth<2.0dev,>=1.21.1, but you'll have google-auth 1.20.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-metadata 0.23.0 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kfac 0.2.2 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: absl-py, jaxlib, torch, gin-config, tensorflow-metadata, dill, promise, termcolor, tensorflow-datasets, mesh-tensorflow, portalocker, sacrebleu, sentencepiece, tokenizers, regex, sacremoses, transformers, grpcio, astunparse, keras-preprocessing, opt-einsum, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tensorboard, google-pasta, gast, tensorflow-estimator, tensorflow, importlib-resources, dm-tree, tfds-nightly, tensorflow-text, rouge-score, t5, funcsigs, jax, pyglet, gym, tf-slim, httplib2, oauth2client, gunicorn, opencv-python, flax, pygame, dopamine-rl, tensorflow-hub, tensorflow-probability, tensorflow-gan, typeguard, tensorflow-addons, pypng, bz2file, kfac, google-api-core, google-auth-httplib2, uritemplate, google-api-python-client, tensor2tensor, trax\n"
     ]
    }
   ],
   "source": [
    "# !pip install trax==1.3.1 #Use this version for this notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # regular ol' numpy\n",
    "\n",
    "from trax import layers as tl  # core building block\n",
    "from trax import shapes  # data signatures: dimensionality and type\n",
    "from trax import fastmath  # uses jax, offers numpy on steroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trax version 1.3.1 or better \n",
    "!pip list | grep trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "Layers are the core building blocks in Trax or as mentioned in the lectures, they are the base classes.\n",
    "\n",
    "They take inputs, compute functions/custom calculations and return outputs.\n",
    "\n",
    "You can also inspect layer properties. Let me show you some examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu Layer\n",
    "First I'll show you how to build a relu activation function as a layer. A layer like this is one of the simplest types. Notice there is no object initialization so it works just like a math function.\n",
    "\n",
    "**Note: Activation functions are also layers in Trax, which might look odd if you have been using other frameworks for a longer time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Layers\n",
    "# Create a relu trax layer\n",
    "relu = tl.Relu()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", relu.name)\n",
    "print(\"expected inputs :\", relu.n_in)\n",
    "print(\"promised outputs :\", relu.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = relu(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Layer\n",
    "Now I'll show you how to build a layer that takes 2 inputs. Notice the change in the expected inputs property from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a concatenate trax layer\n",
    "concat = tl.Concatenate()\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", concat.name)\n",
    "print(\"expected inputs :\", concat.n_in)\n",
    "print(\"promised outputs :\", concat.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x1 :\", x1)\n",
    "print(\"x2 :\", x2, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = concat([x1, x2])\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers are Configurable\n",
    "You can change the default settings of layers. For example, you can change the expected inputs for a concatenate layer from 2 to 3 using the optional parameter `n_items`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure a concatenate layer\n",
    "concat_3 = tl.Concatenate(n_items=3)  # configure the layer's expected inputs\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", concat_3.name)\n",
    "print(\"expected inputs :\", concat_3.n_in)\n",
    "print(\"promised outputs :\", concat_3.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "x3 = x2 * 0.99\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x1 :\", x1)\n",
    "print(\"x2 :\", x2)\n",
    "print(\"x3 :\", x3, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = concat_3([x1, x2, x3])\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: At any point,if you want to refer the function help/ look up the [documentation](https://trax-ml.readthedocs.io/en/latest/) or use help function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tl.Concatenate) #Uncomment this to see the function docstring with explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers can have Weights\n",
    "Some layer types include mutable weights and biases that are used in computation and training. Layers of this type require initialization before use.\n",
    "\n",
    "For example the `LayerNorm` layer calculates normalized data, that is also scaled by weights and biases. During initialization you pass the data shape and data type of the inputs, so the layer can initialize compatible arrays of weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment any of them to see information regarding the function\n",
    "# help(tl.LayerNorm)\n",
    "# help(shapes.signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Layer initialization\n",
    "norm = tl.LayerNorm()\n",
    "# You first must know what the input data will look like\n",
    "x = np.array([0, 1, 2, 3], dtype=\"float\")\n",
    "\n",
    "# Use the input data signature to get shape and type for initializing weights and biases\n",
    "norm.init(shapes.signature(x)) # We need to convert the input datatype from usual tuple to trax ShapeDtype\n",
    "\n",
    "print(\"Normal shape:\",x.shape, \"Data Type:\",type(x.shape))\n",
    "print(\"Shapes Trax:\",shapes.signature(x),\"Data Type:\",type(shapes.signature(x)))\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", norm.name)\n",
    "print(\"expected inputs :\", norm.n_in)\n",
    "print(\"promised outputs :\", norm.n_out)\n",
    "# Weights and biases\n",
    "print(\"weights :\", norm.weights[0])\n",
    "print(\"biases :\", norm.weights[1], \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x)\n",
    "\n",
    "# Outputs\n",
    "y = norm(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "This is where things start getting more interesting!\n",
    "You can create your own custom layers too and define custom functions for computations by using `tl.Fn`. Let me show you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tl.Fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a custom layer\n",
    "# In this example you will create a layer to calculate the input times 2\n",
    "\n",
    "def TimesTwo():\n",
    "    layer_name = \"TimesTwo\" #don't forget to give your custom layer a name to identify\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x):\n",
    "        return x * 2\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "\n",
    "# Test it\n",
    "times_two = TimesTwo()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", times_two.name)\n",
    "print(\"expected inputs :\", times_two.n_in)\n",
    "print(\"promised outputs :\", times_two.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([1, 2, 3])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = times_two(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinators\n",
    "You can combine layers to build more complex layers. Trax provides a set of objects named combinator layers to make this happen. Combinators are themselves layers, so behavior commutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial Combinator\n",
    "This is the most common and easiest to use. For example could build a simple neural network by combining layers into a single layer using the `Serial` combinator. This new layer then acts just like a single layer, so you can inspect intputs, outputs and weights. Or even combine it into another layer! Combinators can then be used as trainable models. _Try adding more layers_\n",
    "\n",
    "**Note:As you must have guessed, if there is serial combinator, there must be a parallel combinator as well. Do try to explore about combinators and other layers from the trax documentation and look at the repo to understand how these layers are written.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tl.Serial)\n",
    "# help(tl.Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serial combinator\n",
    "serial = tl.Serial(\n",
    "    tl.LayerNorm(),         # normalize input\n",
    "    tl.Relu(),              # convert negative values to zero\n",
    "    times_two,              # the custom layer you created above, multiplies the input recieved from above by 2\n",
    "    \n",
    "    ### START CODE HERE\n",
    "#     tl.Dense(n_units=2),  # try adding more layers. eg uncomment these lines\n",
    "#     tl.Dense(n_units=1),  # Binary classification, maybe? uncomment at your own peril\n",
    "#     tl.LogSoftmax()       # Yes, LogSoftmax is also a layer\n",
    "    ### END CODE HERE\n",
    ")\n",
    "\n",
    "# Initialization\n",
    "x = np.array([-2, -1, 0, 1, 2]) #input\n",
    "serial.init(shapes.signature(x)) #initialising serial instance\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial,\"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out)\n",
    "print(\"weights & biases:\", serial.weights, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX\n",
    "Just remember to lookout for which numpy you are using, the regular ol' numpy or Trax's JAX compatible numpy. Both tend to use the alias np so watch those import blocks.\n",
    "\n",
    "**Note:There are certain things which are still not possible in fastmath.numpy which can be done in numpy so you will see in assignments we will switch between them to get our work done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numpy vs fastmath.numpy have different data types\n",
    "# Regular ol' numpy\n",
    "x_numpy = np.array([1, 2, 3])\n",
    "print(\"good old numpy : \", type(x_numpy), \"\\n\")\n",
    "\n",
    "# Fastmath and jax numpy\n",
    "x_jax = fastmath.numpy.array([1, 2, 3])\n",
    "print(\"jax trax numpy : \", type(x_jax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Trax is a concise framework, built on TensorFlow, for end to end machine learning. The key building blocks are layers and combinators. This notebook is just a taste, but sets you up with some key inuitions to take forward into the rest of the course and assignments where you will build end to end models."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
